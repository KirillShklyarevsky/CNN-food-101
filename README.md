# 1) Графики обучения для нейронной сети EfficientNet-B0 с использованием Transfer Learning и техники аугментации данных "Случайное горизонтальное и вертикальное отображение"

 mode - тип отображения.
```
tf.keras.layers.experimental.preprocessing.RandomFlip(mode=HORIZONTAL_AND_VERTICAL)
```

  - Легенда:

   ![](./Images/Flip_Acur.png)
  
   График метрики качества (на валидации):
   ![SVG example](./Images/epoch_categorical_accuracy_1.svg)

  - Легенда:

   ![](./Images/Flip_Loss.png)

  График функции потерь (на валидации):
   ![SVG example](./Images/epoch_loss_1.svg)

Наилучшим параметром отображения оказалось горизонтальное отображение. При нем значения метрики точности достигло 67,58%. На графике функции потерь горизонтального отображения наблюдается наименьшее значение 1,208. 

Результат применения техники аугментации данных "Горизонтальное отображение":

![](./Images/img_horizontal.jpg)

# 2) Графики обучения для нейронной сети EfficientNet-B0 с использованием Transfer Learning и техники аугментации данных "Использование случайной части изображения" 
  
  height - высота выходной формы.
  
  width - ширина выходной формы.
```
tf.keras.layers.experimental.preprocessing.RandomCrop(height, width)
```
 
 Начальными размерами изображения были выбраны: 250x250, 275x275, 300x300, 250x300, 300x250.
 
  - Легенда:

   ![](./Images/Crop_Accur.png)
  
   График метрики качества (на валидации):
   ![SVG example](./Images/epoch_categorical_accuracy_2.svg)
   
   - Легенда:

   ![](./Images/Crop_Loss.png)

  График функции потерь (на валидации):
   ![SVG example](./Images/epoch_loss_2.svg)
   
   Наилучшим параметром изначаьным размером оказался 300x250. При котором значения метрики точности достигло 66,65%. На графике функции потерь наблюдаются наименьшее значение среди других начальных параметров - 1,24. 
   
   Результат применения техники аугментации данных "Использование случайной части изображения" с начальным размером изображения 300x250:

![](./Images/img_crop.jpg)

# 3) Графики обучения для нейронной сети EfficientNet-B0 с использованием Transfer Learning и техники аугментации данных "Поворот на случайный угол"
 
 factor - коэффициент угла случайного поворота  [ -factor * 2pi, factor * 2pi].
 
 fill_mode - режим заполнения точек, находящихся вне исходного изображения.
 
 interpolation - режим интерполяции. 
```
 tf.keras.layers.experimental.preprocessing.RandomRotation(factor, fill_mode='reflect', interpolation='bilinear')
```

  - Легенда:

   ![](./Images/Rot_Accur.png)
  
   График метрики качества (на валидации):
   ![SVG example](./Images/epoch_categorical_accuracy_3.svg)
   
   - Легенда:

   ![](./Images/Rot_Locc.png)

  График функции потерь (на валидации):
   ![SVG example](./Images/epoch_loss_3.svg)
   
   Наилучшим параметром изначаьным размером оказался factor=0.02. При котором значения метрики точности достигло 67,31%. На графике функции потерь наблюдаются наименьшее значение 1,222. 
   
   Результат применения техники аугментации данных "Поворот на случайный угол", factor=0.02:

![](./Images/img_rotation.jpg)
   
   # 4) Графики обучения для нейронной сети EfficientNet-B0 с использованием Transfer Learning и оптимальных техник аугментации данных из пунктов 1-3 совместно. 
  
  - Легенда:

   ![](./Images/Com_Acc.png)
  
   График метрики качества (на валидации):
   ![SVG example](./Images/epoch_categorical_accuracy_4.svg)
   
   - Легенда:

   ![](./Images/Comb_Loss.png)

  График функции потерь (на валидации):
   ![SVG example](./Images/epoch_loss_4.svg)
   
   Результат применения совместных техник аугментации данных:

![](./Images/img_combination.jpg)

# 5) Анализ полученных результатов

   Сравнив наилучший результат для нейронной сети EfficientNet-B0 с использованием Transfer Learning и фиксированного темпа обучения 0,0001 (максимальная точность 67,5% при значении потерь 1,206 из лабораторной работы №3) с результатом совместной реализации оптимальных техник аугментации данных, можно заметить, что точность обучения снизилась на 0,0085%. А так же время достижения максимума точности не сократилось. Совместное использование нескольких техник аугментации данных не привело к улучшению обучения сети. Также наилучшей техникой аугментации со случайно выбранными параметрами оказалась техника горизонтального отображения, которая дала прирост точности на 0,0008% по сравнению с нейронной сетью EfficientNet-B0 с использованием Transfer Learning и фиксированного темпа обучения 0,0001, однако ни одна из техник аугментации данных не дала никаких значимых улучшений.
